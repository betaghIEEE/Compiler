
\subsection {Names in the Symbol Table}

\begin{enumerate}
\item ``Leximes for all tokens are acquired into ST by the lexical analyzer. ''  \cite{ullmanCompillers} The ST has a operator called lookup necessary for finding these leximes.
\item Semantic actions has an operation called emit (gen\_quad).  This operation implants basic operations into the quad table.  
\item When the statement forming a procedure body is examined, a pointer to the symbol table for the procedure appears on top of the table stack.  
\item Given a production for a procedure:
\[ \D \to \textbf {proc id ;} N D_1 ; S \]
``An names in an assignment generated by $S$ must have been declared in either the procedure that $S$ appears in, or in some enclosing procedure.  ''   \cite{ullmanCompillers}  In other words, the scope of statement determines the relevant symbol table paths.  
\item There are critical semantic actions to take in the case of statements involving  assignments, and Turing Essential Operations.    Ordering is determined by syntax, and the calls then determine the semantics.    (Reference figure 8.15 \cite {ullmanCompilers}.
\end{enumerate}

\subsection {Reusing Temporary Names}
What actions should occur with semantic action operation newtemp?  
\begin{enumerate}
\item The operation requests a new entry in the scope's symbol table.    
\item Also, it is with these temporary variables that optimizations can be made.  
\item Where are temporaries generated:
\begin{itemize}
\item Majority in syntax directed translation of expression.  
\item ``The lifetimes of these temporaries are nested like matching pairs of balanced parentheses.  ''    An optimization may involve modifying gentemp (newtemp) such that ``it uses a small array in a procedure's data area to hold the temporaries.''   This array is organized as a stack, and tends to be used in this fashion.  
\end{itemize}
\item ``A reasonable strategy is to create a new name whenever we create an additional definition or use for a temporary or move its computation.''   
\end{enumerate}



\subsection  {Addressing Array Elements}
\begin{enumerate}
\item ``Elements of an array can be accessed quickly if the elements are stored in a block of consecutive locations.''  The equation is 
\[ A [i] = A_{\textsl{base}} + ( i - {\textsl{lower-bound} } ) \times \textsl{width} \]
Various means of computing this equation in the semantic actions can be performed depending on how the declaration of the array is handled.   For example, the algebraic rewrite of $A[i]$ is 
\[ A[i] = A_{\textsl{base}} - \textsl{lower-bound} \times \textsl {width} + i \times \textsl{width} \]
The first sum 
\[ C  = A_{\textsl{base}} - \textsl{lower-bound} \times \textsl {width}  \]  
\item ``Compile-time precalculation can also be applied to address calculations of elements of multi-dimensional arrays.''    This is a classic representation issue that must be addressed in most stages of language and compiler design.    It can obviously be ignored in lexical analysis.   

In most cases, it is simply a matter of define the following parameters
\begin{itemize}
\item Lower bound 
\item Fastest Variance in Subscripts
\end{itemize}
\item A more significant issue in intermediate code generation is generating references for array(s) and their indices.  
\begin{itemize}
\item Left most expression semantic action association:  \\
This idea binds the semantic actions of the array to the first index of the list as opposed to the array identifier itself.  
\item Number of dimensions and array of dimension values must be two properties of the symbol table record(s).  
\item Included in the symbol table must be location and offset of the array.  
\end{itemize}

\end{enumerate}

\subsection {Translation Scheme for Addressing Array Elements}
Diagram for the example.  






\subsection {Type Conversion within Assignment}
\begin{quote}
In practice, there would be many different types of variables and constants, so the compiler must either reject certain mixed-type operations or generate appropriate coercion (type conversion) instructions.  
\end{quote}
This issue is not in the grammar that is being presented in Cooke's class, but is common in procedural languages.  

Figure 8.19 shows the algorithm of Type Conversion for simple addition expressions.   The concept deals with converting arguments into compatible types.  Obviously, there is not always a common type between two arguments.   This issue is critical as data types are allowed to become more complex.    

The example presented by Ullman is relatively simple and present in most commonly used procedural and object oriented languages.  


\subsection {Accessing Fields in Records}
\begin{quote}
The compiler must keep track of both the types and relative addresses of the fields of a record.  An advantage of keeping this information in symbol-table entries for the field names is that the routine for looking up names in the symbol tables can also be used for field names.  
\end{quote}



Note that in all of this, words may have been stated about operations based on type.  However, indirect memory access was not one of them.  